{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a05NN10vDrWj"
   },
   "source": [
    "NLP in 3-Steps: Transform, Transfer and Predict\n",
    "====\n",
    "\n",
    "\n",
    "First, press the `[OPEN IN PLAYGROUND]` button. \n",
    "\n",
    "Then, walk through the jupyter notebook cells with `SHIFT + ENTER` to begin your journey\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7lxVWeaqCotg"
   },
   "source": [
    "# 1. Introduction\n",
    "\n",
    "**Natural Language Processing (NLP)** is the task of making computers understand and produce human languages.\n",
    "\n",
    "**Deep Learning (DL)** is... \n",
    "\n",
    "Some people say it's: \n",
    "\n",
    " - Neural nets\n",
    " - Stacking multiple/deep layers of \"representation learning\"\n",
    " - Something that burns up as much GPUs as Bitcoin mining\n",
    " - A subset of methods in machine learning \n",
    " \n",
    " \n",
    " <br>\n",
    " **Deep Learning in NLP** is lots of arrays of floats.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ieIxgEASDABP"
   },
   "source": [
    "# 2. Vector-Space Model\n",
    "\n",
    "To understand how deep learning approaches is attractive in NLP, first we should understand the notion of **vector space model**. \n",
    "\n",
    "Essentially, vector space models is a **numerical representation of text** (usually an array). \n",
    "\n",
    "Traditionally, it is computed using the number of times each word occurs, e.g.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "faE01x9PDA69"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "sent0 = \"The quick brown fox jumps over the lazy brown dog .\".lower().split()\n",
    "sent1 = \"Mr brown jumps over the lazy fox .\".lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1404,
     "status": "ok",
     "timestamp": 1527818264345,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "lOfy68NUDErF",
    "outputId": "2b551063-94c3-4d2f-906c-1d709db4351d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word counts:\n",
      "Counter({'the': 2, 'brown': 2, 'quick': 1, 'fox': 1, 'jumps': 1, 'over': 1, 'lazy': 1, 'dog': 1, '.': 1})\n",
      "Counter({'mr': 1, 'brown': 1, 'jumps': 1, 'over': 1, 'the': 1, 'lazy': 1, 'fox': 1, '.': 1})\n"
     ]
    }
   ],
   "source": [
    "print('Word counts:')\n",
    "print(Counter(sent0))\n",
    "print(Counter(sent1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3ngOKzCADLd0"
   },
   "source": [
    "### Putting the words and counts into a nice table\n",
    "\n",
    "|  |the | brown | jumps | fox | quick | dog | over | lazy | mr | . | \n",
    "|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n",
    "|Sent0 | 2 | 2 | 1 | 1 | 1 | 1 | 1 | 1 | 0 | 1 | \n",
    "|Sent1 | 1 | 1 | 1 | 1 | 0 | 0 | 1 | 1 | 1 | 1 | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KCP3-TMmDLhc"
   },
   "source": [
    "When we fix the position of the vocabulary in the table, we get the **sentence vectors** <br>\n",
    "(i.e. list of numbers to represent each sentence) **that are comparable across sentences**: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 739,
     "status": "ok",
     "timestamp": 1546884826331,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "",
      "userId": "10744199447724752848"
     },
     "user_tz": -480
    },
    "id": "d4RHC_XyUAR6",
    "outputId": "57d65ce2-0695-4d75-8298-d6f77886f46b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>brown</th>\n",
       "      <th>jumps</th>\n",
       "      <th>fox</th>\n",
       "      <th>quick</th>\n",
       "      <th>dog</th>\n",
       "      <th>over</th>\n",
       "      <th>lazy</th>\n",
       "      <th>mr</th>\n",
       "      <th>.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   the  brown  jumps  fox  quick  dog  over  lazy  mr  .\n",
       "0    2      2      1    1      1    1     1     1   0  1\n",
       "1    1      1      1    1      0    0     1     1   1  1"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "column_names = ['the', 'brown', 'jumps', 'fox', 'quick', 'dog', 'over', 'lazy', 'mr', '.']\n",
    "sent0 = [2,2,1,1,1,1,1,1,0,1]\n",
    "sent1 = [1,1,1,1,0,0,1,1,1,1]\n",
    "\n",
    "matrix = np.array([sent0, sent1]) # We put all documents into a matrix.\n",
    "\n",
    "documents = pd.DataFrame(matrix, columns=column_names)\n",
    "documents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ckl988RINvyv"
   },
   "source": [
    "### Alternatively, without hard-coding the counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 668,
     "status": "ok",
     "timestamp": 1546884830734,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "",
      "userId": "10744199447724752848"
     },
     "user_tz": -480
    },
    "id": "o5Ef9bXr88wV",
    "outputId": "7ae48094-d052-45fa-92b5-2b2eff3f3b85"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.</th>\n",
       "      <th>brown</th>\n",
       "      <th>dog</th>\n",
       "      <th>fox</th>\n",
       "      <th>jumps</th>\n",
       "      <th>lazy</th>\n",
       "      <th>mr</th>\n",
       "      <th>over</th>\n",
       "      <th>quick</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   .  brown  dog  fox  jumps  lazy  mr  over  quick  the\n",
       "0  1      2    1    1      1     1   0     1      1    2\n",
       "1  1      1    0    1      1     1   1     1      0    1"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent0 = \"The quick brown fox jumps over the lazy brown dog .\".lower().split()\n",
    "sent1 = \"Mr brown jumps over the lazy fox .\".lower().split()\n",
    "\n",
    "documents = pd.DataFrame.from_dict([Counter(sent0), Counter(sent1)])\n",
    "documents.fillna(0, inplace=True, downcast='infer')\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cbaypcIMhXFM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 879,
     "status": "ok",
     "timestamp": 1527817789337,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "zNkS0zrhWpqB",
    "outputId": "0ba09cc1-4c2a-4a9a-b6fb-4b070b7e24c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "['mr', 'brown', 'jumps', 'over', 'the', 'lazy', 'fox', '.']\n"
     ]
    }
   ],
   "source": [
    "sent0 = documents.iloc[0]\n",
    "print(type(sent0))\n",
    "print(sent1) # When we want to access the sentence as a pandas.Series object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 782,
     "status": "ok",
     "timestamp": 1527817790595,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "xFvRTOE7VWUn",
    "outputId": "27f7a5aa-d33c-4dee-c707-27686e704b11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[1 2 1 1 1 1 0 1 1 2]\n"
     ]
    }
   ],
   "source": [
    "sent0 = documents.iloc[0]\n",
    "print(type(sent0.values))\n",
    "print(sent0.values) # When we want to access the sentence as a numpy.array object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 738,
     "status": "ok",
     "timestamp": 1527817791785,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "JPAsIwWBPDCP",
    "outputId": "4a3efb27-6ec1-4101-f9b3-7af16fb7f794"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       ".        1\n",
       "brown    2\n",
       "dog      1\n",
       "fox      1\n",
       "jumps    1\n",
       "lazy     1\n",
       "mr       0\n",
       "over     1\n",
       "quick    1\n",
       "the      2\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wZ_Q_f8zUCKs"
   },
   "source": [
    "\n",
    "Conversely, if we flip the table around we get a **vector representation of each word** too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 780,
     "status": "ok",
     "timestamp": 1527817793216,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "3yW92KzvDPjh",
    "outputId": "770ede7f-0362-446a-dd78-93994a738ae5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.</th>\n",
       "      <th>brown</th>\n",
       "      <th>dog</th>\n",
       "      <th>fox</th>\n",
       "      <th>jumps</th>\n",
       "      <th>lazy</th>\n",
       "      <th>mr</th>\n",
       "      <th>over</th>\n",
       "      <th>quick</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   .  brown  dog  fox  jumps  lazy  mr  over  quick  the\n",
       "0  1      2    1    1      1     1   0     1      1    2\n",
       "1  1      1    0    1      1     1   1     1      0    1"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 880,
     "status": "ok",
     "timestamp": 1527817794874,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "7k50FDRKUMs7",
    "outputId": "420797fb-b52b-4cd5-a2d8-c543eb608ea8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1]\n"
     ]
    }
   ],
   "source": [
    "print(documents['the'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1442,
     "status": "ok",
     "timestamp": 1527817797058,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "UvmvSa7nW0pQ",
    "outputId": "e36c7dfb-ec37-4c27-f708-4d2f42e786ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1]\n"
     ]
    }
   ],
   "source": [
    "print(documents['over'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3cPrTgtYXEzv"
   },
   "source": [
    "## 2.1 Term-Frequency / Inverse Document Frequency (TF-IDF)\n",
    "\n",
    "Traditionally, if we look at the word count tables `documents` above from the column perspective, <br>\n",
    "it shows the raw count of each word in each document. \n",
    "\n",
    "The simplest **term-frequency** defintion is the number of occurences of each word per sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1143,
     "status": "ok",
     "timestamp": 1527817799366,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "HtFoldx0W3w-",
    "outputId": "21c54d51-8da2-45c3-b2f1-81fa4f086e6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term-Frequency (TF) of \"brown\" in sent0 = 2\n",
      "Term-Frequency (TF) of \"brown\" in sent1 = 1\n"
     ]
    }
   ],
   "source": [
    "word = 'brown'\n",
    "print(f'Term-Frequency (TF) of \"{word}\" in sent0 =', documents[word].values[0])\n",
    "print(f'Term-Frequency (TF) of \"{word}\" in sent1 =', documents[word].values[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g6Tx2Zg4nT5V"
   },
   "source": [
    "Using the raw counts to denote TF allows the values in the table to range from `[0, ∞]`, <br>\n",
    "that might cause some numerical instability, so typically we <br>\n",
    "**normalize the raw counts by the total count of the words across all sentences**; <br>\n",
    "that way we limit the range of values to `[0, 1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NbgyqAw1nSr5"
   },
   "outputs": [],
   "source": [
    "documents = documents.apply(lambda x: x/sum(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k7jdqNyX5OqW"
   },
   "source": [
    "Another numerical statistics that is useful to represent the word is the **document-frequency**. \n",
    "\n",
    "The document-frequency is simply the no. of documents that a word occurs in. <br>\n",
    "So, for each word, there will be only 1 document-frequency value.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 773,
     "status": "ok",
     "timestamp": 1527817802509,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "5uyGOUya55Q4",
    "outputId": "bd01b33b-2546-4ec6-81b4-64e93b4fd8cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document-Frequency (DF) of \"brown\" = 2\n",
      "The \"brown\" word appears in these sentences: [0 1]\n"
     ]
    }
   ],
   "source": [
    "word = 'brown'\n",
    "# Note: `documents['the'].nonzero()[0]`  returns an index of the sentence with non-zero value.\n",
    "print(f'Document-Frequency (DF) of \"{word}\" =', len(documents[word].nonzero()[0]))\n",
    "print(f'The \"{word}\" word appears in these sentences:', documents[word].nonzero()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 832,
     "status": "ok",
     "timestamp": 1527817803788,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "c_mZLowRP1-v",
    "outputId": "cf13446e-732f-4581-986b-4a038a772793"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[word].nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1527817805008,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "jJnmBnrEAWnk",
    "outputId": "3c2ed735-e451-4ba0-ae7f-7d8d02e4f3e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document-Frequency (DF) of \"mr\" = 1\n",
      "The \"mr\" word appears in these sentences: [1]\n"
     ]
    }
   ],
   "source": [
    "word = 'mr'\n",
    "print(f'Document-Frequency (DF) of \"{word}\" =', len(documents[word].nonzero()[0]))\n",
    "print(f'The \"{word}\" word appears in these sentences:', documents[word].nonzero()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8nllxoaA5oD4"
   },
   "source": [
    "While term-frequency tells you how often a word occurs per sentence, <br>\n",
    "*the information is localized to the word per sentence*. \n",
    "\n",
    "The document-frequency tells you how often a word will occur in the whole collection of sentences, <br>\n",
    "*the information is global and not specific to any sentence*.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WHRiYF6mBzDK"
   },
   "source": [
    "\n",
    "\n",
    "A useful statistics that combines both term/document-frequencies is the<br>\n",
    "**term-frequency / inverse document-frequency** (TF-IDF) number.<br><br>\n",
    "\n",
    "The **inverse document frequency** , like document-frequency is a global statistics; it's  the <br>\n",
    "logarithm of the no. of sentences divided by the no. of sentences that the word occurs in. \n",
    "\n",
    "For word \"fox\", the `idf` value is:\n",
    "\n",
    "```\n",
    "idf_fox = log(N/n_fox)\n",
    "```\n",
    "\n",
    "where, \n",
    "\n",
    "- `N` = no. of sentences in the whole dataset\n",
    "- `n_w` = no. of sentences contains a particular word `fox`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 920,
     "status": "ok",
     "timestamp": 1527744535534,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "Q2YORYkl5OYj",
    "outputId": "7b410dd5-1bbc-48b4-cbd2-2d2c7fffefdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The \"brown\" word appears in these sentences: [0 1]\n",
      "Inverse Document-Frequency (IDF) of \"brown\" = 0.0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "word = 'brown'\n",
    "print(f'The \"{word}\" word appears in these sentences:', documents[word].nonzero()[0])\n",
    "\n",
    "word_df = len(documents[word].nonzero()[0])\n",
    "num_sentences, num_words = documents.shape\n",
    "word_idf = math.log(num_sentences/word_df)\n",
    "print(f'Inverse Document-Frequency (IDF) of \"{word}\" =', word_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1383,
     "status": "ok",
     "timestamp": 1527744538184,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "3lkA4cvMZw1p",
    "outputId": "b1674877-57bd-4486-edd0-e680fb8a0ab2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The \"mr\" word appears in these sentences: [1]\n",
      "Inverse Document-Frequency (IDF) of \"mr\" = 0.6931471805599453\n"
     ]
    }
   ],
   "source": [
    "word = 'mr'\n",
    "print(f'The \"{word}\" word appears in these sentences:', documents[word].nonzero()[0])\n",
    "\n",
    "word_df = len(documents[word].nonzero()[0])\n",
    "num_sentences, num_words = documents.shape\n",
    "word_idf = math.log(num_sentences/word_df)\n",
    "print(f'Inverse Document-Frequency (IDF) of \"{word}\" =', word_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 834,
     "status": "ok",
     "timestamp": 1527744539753,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "imfkXHNmEJfb",
    "outputId": "a22d0d06-8b18-4afe-b933-773944ac7ed7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDF of \".\" \t= 0.0\n",
      "IDF of \"brown\" \t= 0.0\n",
      "IDF of \"dog\" \t= 0.6931471805599453\n",
      "IDF of \"fox\" \t= 0.0\n",
      "IDF of \"jumps\" \t= 0.0\n",
      "IDF of \"lazy\" \t= 0.0\n",
      "IDF of \"mr\" \t= 0.6931471805599453\n",
      "IDF of \"over\" \t= 0.0\n",
      "IDF of \"quick\" \t= 0.6931471805599453\n",
      "IDF of \"the\" \t= 0.0\n"
     ]
    }
   ],
   "source": [
    "# To compute the IDF for all words.\n",
    "num_sentences, num_words = documents.shape\n",
    "\n",
    "word2idf = {}   # Lets save a dictionary to map the words to their IDFs\n",
    "idf_vector = [] # Lets save an ordered list of IDFS w.r.t. order of the column names.\n",
    "\n",
    "for word in documents:\n",
    "  word_idf = math.log(num_sentences/len(documents[word].nonzero()[0]))\n",
    "  word2idf[word] = word_idf\n",
    "  idf_vector.append(word_idf)\n",
    "  print(f'IDF of \"{word}\" \\t=', word_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZPGoPDuuEk4E"
   },
   "source": [
    "**Note:** We see that the IDF values for the words that occur in all sentences is 0 while the words that occur in one sentence is 0.693...\n",
    "\n",
    "<br> \n",
    "For more details, take a look at the \n",
    "\n",
    " - [Wikipedia post on TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)\n",
    " - [Stanford tutorial on IDF](https://nlp.stanford.edu/IR-book/html/htmledition/inverse-document-frequency-1.html)\n",
    "\n",
    "**Is it necessary to take the logarithm?**\n",
    "\n",
    "Actually, I think it's not necessary in theory but taking the log makes the computation later on more stable since we can avoid huge numbers that might cause overflow and we can add log probabilities rather than multiply probabilities. \n",
    "\n",
    "For more discussions, I've started a thread on https://mailman.uib.no/public/corpora/2018-June/thread.html \n",
    "  \n",
    "   \n",
    "  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 835,
     "status": "ok",
     "timestamp": 1527744541138,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "LzwQCrzyhQIT",
    "outputId": "e7a48def-15f3-4208-e41d-40ca93e8808a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.</th>\n",
       "      <th>brown</th>\n",
       "      <th>dog</th>\n",
       "      <th>fox</th>\n",
       "      <th>jumps</th>\n",
       "      <th>lazy</th>\n",
       "      <th>mr</th>\n",
       "      <th>over</th>\n",
       "      <th>quick</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     .  brown       dog  fox  jumps  lazy        mr  over     quick  the\n",
       "0  0.0    0.0  0.693147  0.0    0.0   0.0  0.000000   0.0  0.693147  0.0\n",
       "1  0.0    0.0  0.000000  0.0    0.0   0.0  0.693147   0.0  0.000000  0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_tfidf_dict = {}\n",
    "\n",
    "# Iterate through each word in the vocabulary.\n",
    "for word in documents:\n",
    "  tf = documents[word] # Retrieve the term-frequency.\n",
    "  idf = word2idf[word] # Retrieve the inverse doc-frequency.\n",
    "  tfidf = tf*idf       # Compute the TF-IDF value.\n",
    "  documents_tfidf_dict[word] = tfidf\n",
    "  \n",
    "pd.DataFrame.from_dict(documents_tfidf_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 893,
     "status": "ok",
     "timestamp": 1527744547274,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "P9VHtcOTUC_2",
    "outputId": "288be372-59e6-4cd1-d037-1fbc5c25e63b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.69314718, 0.        , 0.        ,\n",
       "       0.        , 0.69314718, 0.        , 0.69314718, 0.        ])"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#documents\n",
    "np.array(idf_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 828,
     "status": "ok",
     "timestamp": 1527744548638,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "_K-qvGyRGIyQ",
    "outputId": "9e529389-da08-4161-a9b6-8d724fb9c21e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.</th>\n",
       "      <th>brown</th>\n",
       "      <th>dog</th>\n",
       "      <th>fox</th>\n",
       "      <th>jumps</th>\n",
       "      <th>lazy</th>\n",
       "      <th>mr</th>\n",
       "      <th>over</th>\n",
       "      <th>quick</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     .  brown       dog  fox  jumps  lazy        mr  over     quick  the\n",
       "0  0.0    0.0  0.693147  0.0    0.0   0.0  0.000000   0.0  0.693147  0.0\n",
       "1  0.0    0.0  0.000000  0.0    0.0   0.0  0.693147   0.0  0.000000  0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can use some matrix/vector tricks to multiply each column by the respective IDF.\n",
    "# `documents.as_matrix() * np.array(idf_vector)`\n",
    "\n",
    "documents_tfidf = pd.DataFrame(documents.as_matrix() * np.array(idf_vector), \n",
    "                               columns=list(documents))\n",
    "documents_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pGKBPYUKuv48"
   },
   "source": [
    "**Note:** \n",
    "\n",
    "- `0.0` means that the word is not helpful in differentiating between the documents. \n",
    "- And for the instances where the value is  `0.693147`, it's because they appear only once in the document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yAXhggQpGHrj"
   },
   "source": [
    "### Lets add a few more sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1125,
     "status": "ok",
     "timestamp": 1527744552202,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "YYrjIIQxEj6A",
    "outputId": "8f632a8c-2bf5-4762-bf4f-72d1008990bd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>,</th>\n",
       "      <th>.</th>\n",
       "      <th>are</th>\n",
       "      <th>brown</th>\n",
       "      <th>chocolates</th>\n",
       "      <th>dog</th>\n",
       "      <th>fox</th>\n",
       "      <th>frank</th>\n",
       "      <th>jumps</th>\n",
       "      <th>lazy</th>\n",
       "      <th>mr</th>\n",
       "      <th>over</th>\n",
       "      <th>quick</th>\n",
       "      <th>red</th>\n",
       "      <th>roses</th>\n",
       "      <th>the</th>\n",
       "      <th>through</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ,     .  are  brown  chocolates  dog  fox  frank     jumps  lazy   mr  \\\n",
       "0  0.0  0.25  0.0   0.50         0.0  0.5  0.5    0.0  0.333333   0.5  0.0   \n",
       "1  0.0  0.25  0.0   0.25         0.0  0.0  0.5    0.0  0.333333   0.5  1.0   \n",
       "2  1.0  0.25  1.0   0.25         1.0  0.0  0.0    0.0  0.000000   0.0  0.0   \n",
       "3  0.0  0.25  0.0   0.00         0.0  0.5  0.0    1.0  0.333333   0.0  0.0   \n",
       "\n",
       "   over  quick  red  roses       the  through  \n",
       "0   0.5    1.0  0.0    0.0  0.333333      0.0  \n",
       "1   0.5    0.0  0.0    0.0  0.166667      0.0  \n",
       "2   0.0    0.0  0.5    0.5  0.166667      0.0  \n",
       "3   0.0    0.0  0.5    0.5  0.333333      1.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternatively, without hard-coding the counts.\n",
    "\n",
    "sent0 = \"The quick brown fox jumps over the lazy brown dog .\".lower().split()\n",
    "sent1 = \"Mr brown jumps over the lazy fox .\".lower().split()\n",
    "sent2 = \"Roses are red , the chocolates are brown .\".lower().split()\n",
    "sent3 = \"The frank dog jumps through the red roses .\".lower().split()\n",
    "\n",
    "documents = pd.DataFrame.from_dict(list(map(Counter, [sent0, sent1, sent2, sent3])))\n",
    "documents.fillna(0, inplace=True, downcast='infer')\n",
    "documents = documents.apply(lambda x: x/sum(x))  # Normalize the TF.\n",
    "documents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 757,
     "status": "ok",
     "timestamp": 1527744553582,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "ZNZYWPnWFlXr",
    "outputId": "f5d36b8b-b75f-4ea2-c380-6d219b34d434"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDF of \",\" \t= 1.3862943611198906\n",
      "IDF of \".\" \t= 0.0\n",
      "IDF of \"are\" \t= 1.3862943611198906\n",
      "IDF of \"brown\" \t= 0.28768207245178085\n",
      "IDF of \"chocolates\" \t= 1.3862943611198906\n",
      "IDF of \"dog\" \t= 0.6931471805599453\n",
      "IDF of \"fox\" \t= 0.6931471805599453\n",
      "IDF of \"frank\" \t= 1.3862943611198906\n",
      "IDF of \"jumps\" \t= 0.28768207245178085\n",
      "IDF of \"lazy\" \t= 0.6931471805599453\n",
      "IDF of \"mr\" \t= 1.3862943611198906\n",
      "IDF of \"over\" \t= 0.6931471805599453\n",
      "IDF of \"quick\" \t= 1.3862943611198906\n",
      "IDF of \"red\" \t= 0.6931471805599453\n",
      "IDF of \"roses\" \t= 0.6931471805599453\n",
      "IDF of \"the\" \t= 0.0\n",
      "IDF of \"through\" \t= 1.3862943611198906\n"
     ]
    }
   ],
   "source": [
    "# To compute the IDF for all words.\n",
    "num_sentences, num_words = documents.shape\n",
    "\n",
    "word2idf = {}   # Lets save a dictionary to map the words to their IDFs\n",
    "idf_vector = [] # Lets save an ordered list of IDFS w.r.t. order of the column names.\n",
    "\n",
    "for word in documents:\n",
    "  word_idf = math.log(num_sentences/len(documents[word].nonzero()[0]))\n",
    "  word2idf[word] = word_idf\n",
    "  idf_vector.append(word_idf)\n",
    "  print(f'IDF of \"{word}\" \\t=', word_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1366,
     "status": "ok",
     "timestamp": 1527744555482,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "AqIDvV_E5MT6",
    "outputId": "b949658c-f1de-4240-8f4b-8965a5710eed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>,</th>\n",
       "      <th>.</th>\n",
       "      <th>are</th>\n",
       "      <th>brown</th>\n",
       "      <th>chocolates</th>\n",
       "      <th>dog</th>\n",
       "      <th>fox</th>\n",
       "      <th>frank</th>\n",
       "      <th>jumps</th>\n",
       "      <th>lazy</th>\n",
       "      <th>mr</th>\n",
       "      <th>over</th>\n",
       "      <th>quick</th>\n",
       "      <th>red</th>\n",
       "      <th>roses</th>\n",
       "      <th>the</th>\n",
       "      <th>through</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143841</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.346574</td>\n",
       "      <td>0.346574</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095894</td>\n",
       "      <td>0.346574</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.346574</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071921</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.346574</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095894</td>\n",
       "      <td>0.346574</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.346574</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.071921</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.346574</td>\n",
       "      <td>0.346574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.346574</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.095894</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.346574</td>\n",
       "      <td>0.346574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ,    .       are     brown  chocolates       dog       fox  \\\n",
       "0  0.000000  0.0  0.000000  0.143841    0.000000  0.346574  0.346574   \n",
       "1  0.000000  0.0  0.000000  0.071921    0.000000  0.000000  0.346574   \n",
       "2  1.386294  0.0  1.386294  0.071921    1.386294  0.000000  0.000000   \n",
       "3  0.000000  0.0  0.000000  0.000000    0.000000  0.346574  0.000000   \n",
       "\n",
       "      frank     jumps      lazy        mr      over     quick       red  \\\n",
       "0  0.000000  0.095894  0.346574  0.000000  0.346574  1.386294  0.000000   \n",
       "1  0.000000  0.095894  0.346574  1.386294  0.346574  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.346574   \n",
       "3  1.386294  0.095894  0.000000  0.000000  0.000000  0.000000  0.346574   \n",
       "\n",
       "      roses  the   through  \n",
       "0  0.000000  0.0  0.000000  \n",
       "1  0.000000  0.0  0.000000  \n",
       "2  0.346574  0.0  0.000000  \n",
       "3  0.346574  0.0  1.386294  "
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the TF-IDF table.\n",
    "documents_tfidf = pd.DataFrame(documents.as_matrix() * np.array(idf_vector), \n",
    "                               columns=list(documents))\n",
    "documents_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KQA1Hp7pvXOC"
   },
   "source": [
    "**Note:** Now, we see more cells with different values. The higher they are the more salient/prominent the word is w.r.t. (with respect to) the sentence and across sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mfpCVI_zNJwI"
   },
   "source": [
    "## 2.1.1 TF-IDF with numpy \"natively\"\n",
    "\n",
    "To summarize the above, we can easily achieve our TF-IDF table using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 945,
     "status": "ok",
     "timestamp": 1527744557298,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "Emgb-SsIAgP5",
    "outputId": "4550b6fb-d1b0-4779-c369-1d4a3dc7ebde"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>,</th>\n",
       "      <th>.</th>\n",
       "      <th>are</th>\n",
       "      <th>brown</th>\n",
       "      <th>chocolates</th>\n",
       "      <th>dog</th>\n",
       "      <th>fox</th>\n",
       "      <th>frank</th>\n",
       "      <th>jumps</th>\n",
       "      <th>lazy</th>\n",
       "      <th>mr</th>\n",
       "      <th>over</th>\n",
       "      <th>quick</th>\n",
       "      <th>red</th>\n",
       "      <th>roses</th>\n",
       "      <th>the</th>\n",
       "      <th>through</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143841</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.346574</td>\n",
       "      <td>0.346574</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095894</td>\n",
       "      <td>0.346574</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.346574</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071921</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.346574</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095894</td>\n",
       "      <td>0.346574</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.346574</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.071921</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.346574</td>\n",
       "      <td>0.346574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.346574</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.095894</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.346574</td>\n",
       "      <td>0.346574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ,    .       are     brown  chocolates       dog       fox  \\\n",
       "0  0.000000  0.0  0.000000  0.143841    0.000000  0.346574  0.346574   \n",
       "1  0.000000  0.0  0.000000  0.071921    0.000000  0.000000  0.346574   \n",
       "2  1.386294  0.0  1.386294  0.071921    1.386294  0.000000  0.000000   \n",
       "3  0.000000  0.0  0.000000  0.000000    0.000000  0.346574  0.000000   \n",
       "\n",
       "      frank     jumps      lazy        mr      over     quick       red  \\\n",
       "0  0.000000  0.095894  0.346574  0.000000  0.346574  1.386294  0.000000   \n",
       "1  0.000000  0.095894  0.346574  1.386294  0.346574  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.346574   \n",
       "3  1.386294  0.095894  0.000000  0.000000  0.000000  0.000000  0.346574   \n",
       "\n",
       "      roses  the   through  \n",
       "0  0.000000  0.0  0.000000  \n",
       "1  0.000000  0.0  0.000000  \n",
       "2  0.346574  0.0  0.000000  \n",
       "3  0.346574  0.0  1.386294  "
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent0 = \"The quick brown fox jumps over the lazy brown dog .\".lower().split()\n",
    "sent1 = \"Mr brown jumps over the lazy fox .\".lower().split()\n",
    "sent2 = \"Roses are red , the chocolates are brown .\".lower().split()\n",
    "sent3 = \"The frank dog jumps through the red roses .\".lower().split()\n",
    "\n",
    "documents = pd.DataFrame.from_dict(list(map(Counter, [sent0, sent1, sent2, sent3])))\n",
    "documents.fillna(0, inplace=True, downcast='infer')\n",
    "documents = documents.apply(lambda x: x/sum(x))  # Normalize the TF.\n",
    "documents.head()\n",
    "\n",
    "# To compute the IDF for all words.\n",
    "num_sentences, num_words = documents.shape\n",
    "\n",
    "idf_vector = [] # Lets save an ordered list of IDFS w.r.t. order of the column names.\n",
    "\n",
    "for word in documents:\n",
    "  word_idf = math.log(num_sentences/len(documents[word].nonzero()[0]))\n",
    "  idf_vector.append(word_idf)\n",
    "\n",
    "# Compute the TF-IDF table.\n",
    "documents_tfidf = pd.DataFrame(documents.as_matrix() * np.array(idf_vector), \n",
    "                               columns=list(documents))\n",
    "documents_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YBHT9ur6it3o"
   },
   "source": [
    "\n",
    "## 2.1.2 Use `Gensim` for TF-IDF\n",
    "\n",
    "It's nice to appreciate the computation of TF-IDF given the explanation above\n",
    "\n",
    "But I would advise **AGAINST** using the code above in realistic NLP outside of a tutorial. \n",
    "\n",
    "Instead use the well-optimized `gensim` library for computing the https://radimrehurek.com/gensim/tutorial.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-gW2lmr0j8u2"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zniy0Ka1Sp3s"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 760,
     "status": "ok",
     "timestamp": 1546885052836,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "",
      "userId": "10744199447724752848"
     },
     "user_tz": -480
    },
    "id": "tyTvn17U_1T5",
    "outputId": "50f123e3-afc0-46f5-f136-8dec854809c8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dog</th>\n",
       "      <th>mr</th>\n",
       "      <th>quick</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dog   mr     quick\n",
       "0  0.707107  0.0  0.707107\n",
       "1  0.000000  1.0  0.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import TfidfModel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "sent0 = \"The quick brown fox jumps over the lazy brown dog .\".lower().split()\n",
    "sent1 = \"Mr brown jumps over the lazy fox .\".lower().split()\n",
    "#sent2 = \"Roses are red , the chocolates are brown .\".lower().split()\n",
    "#sent3 = \"The frank dog jumps through the red roses .\".lower().split()\n",
    "\n",
    "dataset = [sent0, sent1]#, sent2, sent3]\n",
    "vocab = Dictionary(dataset)\n",
    "corpus = [vocab.doc2bow(sent) for sent in dataset] \n",
    "model = TfidfModel(corpus)\n",
    "\n",
    "# To retrieve the same pd.DataFrame format.\n",
    "documents_tfidf_lol = [{vocab[word_idx]:tfidf_value \n",
    "                        for word_idx, tfidf_value in sent} \n",
    "                       for sent in model[corpus]]\n",
    "documents_tfidf = pd.DataFrame(documents_tfidf_lol)\n",
    "documents_tfidf.fillna(0, inplace=True)\n",
    "\n",
    "documents_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ERXxBDkbKlC5"
   },
   "source": [
    "## 2.1.3 Using `sklearn` for TF-IDF\n",
    "\n",
    "See http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 681,
     "status": "ok",
     "timestamp": 1546885072335,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "",
      "userId": "10744199447724752848"
     },
     "user_tz": -480
    },
    "id": "j7b-4L2eKkN8",
    "outputId": "6140f58c-412a-48bf-a720-dd12d6b55ca8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brown</th>\n",
       "      <th>dog</th>\n",
       "      <th>fox</th>\n",
       "      <th>jumps</th>\n",
       "      <th>lazy</th>\n",
       "      <th>mr</th>\n",
       "      <th>over</th>\n",
       "      <th>quick</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.500773</td>\n",
       "      <td>0.351909</td>\n",
       "      <td>0.250386</td>\n",
       "      <td>0.250386</td>\n",
       "      <td>0.250386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250386</td>\n",
       "      <td>0.351909</td>\n",
       "      <td>0.500773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.354100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.354100</td>\n",
       "      <td>0.354100</td>\n",
       "      <td>0.354100</td>\n",
       "      <td>0.497675</td>\n",
       "      <td>0.354100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.354100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      brown       dog       fox     jumps      lazy        mr      over  \\\n",
       "0  0.500773  0.351909  0.250386  0.250386  0.250386  0.000000  0.250386   \n",
       "1  0.354100  0.000000  0.354100  0.354100  0.354100  0.497675  0.354100   \n",
       "\n",
       "      quick       the  \n",
       "0  0.351909  0.500773  \n",
       "1  0.000000  0.354100  "
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from scipy.sparse.csr import csr_matrix\n",
    "\n",
    "\n",
    "# The *TfidfVectorizer* from sklearn expects list of strings as input.\n",
    "sent0 = \"The quick brown fox jumps over the lazy brown dog .\".lower()\n",
    "sent1 = \"Mr brown jumps over the lazy fox .\".lower()\n",
    "#sent2 = \"Roses are red , the chocolates are brown .\".lower()\n",
    "#sent3 = \"The frank dog jumps through the red roses .\".lower()\n",
    "\n",
    "dataset = [sent0, sent1]# sent2, sent3]\n",
    "\n",
    "vectorizer = TfidfVectorizer(input=dataset, analyzer='word', ngram_range=(1,1),\n",
    "                     min_df = 0, stop_words=None)\n",
    "tfidf_matrix =  vectorizer.fit_transform(dataset)\n",
    "\n",
    "# Format the TF-IDF table into the pd.DataFrame format.\n",
    "vocab = vectorizer.get_feature_names()\n",
    "documents_tfidf_lol = [{word:tfidf_value for word, tfidf_value in zip(vocab, sent)} \n",
    "                       for sent in tfidf_matrix.toarray()]\n",
    "\n",
    "documents_tfidf = pd.DataFrame(documents_tfidf_lol)\n",
    "documents_tfidf.fillna(0, inplace=True)\n",
    "\n",
    "documents_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H-XbQUMiv7IW"
   },
   "source": [
    "**Note:** The values are different from the ones we have computed with native `numpy` because different definitions of how TF and IDF is computed and different variations of parameters. Nevertheless we see the same trend in how salient/prominent a word is w.r.t. to the sentence and across sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2lC1FDJGXr_V"
   },
   "source": [
    "### TF-IDF beyond single words\n",
    "\n",
    "\n",
    "Instead of transforming the sentences into the TF-IDF values for each word, <br>\n",
    "you can extract the TF-IDF for `n-grams`, think of of as phrases of size `n`. \n",
    "\n",
    "**Note:** that `n-grams` are neither coherent phrases nor linguistically sound elements,  they are just nice features that we can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1091,
     "status": "ok",
     "timestamp": 1527744581076,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "IEtIjXvCYPzS",
    "outputId": "90b7de71-2fb0-4c09-e335-3c0b5331f4c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 'quick'),\n",
       " ('quick', 'brown'),\n",
       " ('brown', 'fox'),\n",
       " ('fox', 'jumps'),\n",
       " ('jumps', 'over'),\n",
       " ('over', 'the'),\n",
       " ('the', 'lazy'),\n",
       " ('lazy', 'brown'),\n",
       " ('brown', 'dog'),\n",
       " ('dog', '.')]"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of n-grams where n=2, we call these bi-grams\n",
    "from nltk import ngrams\n",
    "\n",
    "_sent0 = \"The quick brown fox jumps over the lazy brown dog .\".lower().split()\n",
    "list(ngrams(_sent0, n=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ijC3QvlJYztl"
   },
   "source": [
    "### To extract n-gram TF-IDF, simply change the `ngram_range` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 760,
     "status": "ok",
     "timestamp": 1546885991746,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "",
      "userId": "10744199447724752848"
     },
     "user_tz": -480
    },
    "id": "AV9n7cfIXi0H",
    "outputId": "df3e80c5-29a4-40f0-8ccc-1f6e2661d2e4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brown dog</th>\n",
       "      <th>brown fox</th>\n",
       "      <th>brown jumps</th>\n",
       "      <th>fox jumps</th>\n",
       "      <th>jumps over</th>\n",
       "      <th>lazy brown</th>\n",
       "      <th>lazy fox</th>\n",
       "      <th>mr brown</th>\n",
       "      <th>over the</th>\n",
       "      <th>quick brown</th>\n",
       "      <th>the lazy</th>\n",
       "      <th>the quick</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.364693</td>\n",
       "      <td>0.364693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.364693</td>\n",
       "      <td>0.259482</td>\n",
       "      <td>0.364693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.259482</td>\n",
       "      <td>0.364693</td>\n",
       "      <td>0.259482</td>\n",
       "      <td>0.364693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.470426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.334712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.470426</td>\n",
       "      <td>0.470426</td>\n",
       "      <td>0.334712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.334712</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   brown dog  brown fox  brown jumps  fox jumps  jumps over  lazy brown  \\\n",
       "0   0.364693   0.364693     0.000000   0.364693    0.259482    0.364693   \n",
       "1   0.000000   0.000000     0.470426   0.000000    0.334712    0.000000   \n",
       "\n",
       "   lazy fox  mr brown  over the  quick brown  the lazy  the quick  \n",
       "0  0.000000  0.000000  0.259482     0.364693  0.259482   0.364693  \n",
       "1  0.470426  0.470426  0.334712     0.000000  0.334712   0.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(input=dataset, analyzer='word', \n",
    "                             ngram_range=(2,2), # Bi-grams, 2 words.\n",
    "                             min_df = 0, stop_words=None)\n",
    "tfidf_matrix =  vectorizer.fit_transform(dataset)\n",
    "\n",
    "# Format the TF-IDF table into the pd.DataFrame format.\n",
    "vocab = vectorizer.get_feature_names()\n",
    "documents_tfidf_lol = [{word:tfidf_value for word, tfidf_value in zip(vocab, sent)} \n",
    "                       for sent in tfidf_matrix.toarray()]\n",
    "\n",
    "documents_tfidf = pd.DataFrame(documents_tfidf_lol)\n",
    "documents_tfidf.fillna(0, inplace=True)\n",
    "\n",
    "documents_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EipNchQj4ON-"
   },
   "source": [
    "## 2.2 Where on earth is \"mr brown\"?\n",
    "\n",
    "Lets try an easy task of assigning positive labels to sentences where `mr brown` is in the sentence and negative labels otherwise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CUm0Ij_T3mRw"
   },
   "outputs": [],
   "source": [
    "# Train sentences.\n",
    "sent0, label0 = \"The quick brown fox jumps over the lazy brown dog .\".lower() , False\n",
    "sent1, label1 = \"Mr brown jumps over the lazy fox .\".lower(), True\n",
    "sent2, label2 = \"Roses are red , the chocolates are brown .\".lower(), False\n",
    "sent3, label3 = \"The frank dog jumps through the red roses .\".lower(), False\n",
    "\n",
    "# Test sentences.\n",
    "sent4, label4 = \"Mr Tan jumps on red chocolates ?\".lower(), False\n",
    "sent5, label5 = \"Mr brown likes the lazy dog .\".lower(), True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "50Aybuix5QrY"
   },
   "source": [
    "First, lets write a simple \"classifier\" to predict `mr brown` existence with an **if-else** clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 818,
     "status": "ok",
     "timestamp": 1527744590807,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "3z5jcNCt5QR5",
    "outputId": "ec00ae3b-4cb5-47b2-9ad1-4e8b1e13cae7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mr tan jumps on red chocolates ? \t False False\n",
      "mr brown likes the lazy dog . \t True True\n"
     ]
    }
   ],
   "source": [
    "train_documents = [(sent0, label0), (sent1, label1), (sent2, label2), (sent0, label2)]\n",
    "test_documents = [(sent4, label4), (sent5, label5)]\n",
    "\n",
    "train_texts, train_labels = zip(*train_documents)\n",
    "test_texts, test_labels = zip(*test_documents)\n",
    "\n",
    "for sent, actual_label in test_documents:\n",
    "  predicted_label = 'mr brown' in sent\n",
    "  print(sent, '\\t', predicted_label, actual_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w7sa3utu5N2X"
   },
   "source": [
    "## 2.2.1 `Transform`: Documents to TF-IDF vectors\n",
    "\n",
    "Lets get \"sophisticated\" and try to learn a classifier to predict presence of `mr brown` without explicitly checking the string.\n",
    "\n",
    "Using what we've learnt, lets use `sklearn` TF-IDF representation of the sentences as the training input to train a classifier. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P_1dbrbdzDFe"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from scipy.sparse.csr import csr_matrix\n",
    "\n",
    "vectorizer = TfidfVectorizer(input=train_texts, analyzer='word', \n",
    "                             ngram_range=(1,1), # Note this parameter!\n",
    "                             min_df = 0, stop_words=None)\n",
    "\n",
    "X_train =  vectorizer.fit_transform(train_texts)\n",
    "X_test =  vectorizer.transform(test_texts)\n",
    "\n",
    "y_train = train_labels\n",
    "y_test = test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S8gAJwUzKF_n"
   },
   "source": [
    "**Why `sklearn` not `gensim`?**\n",
    "\n",
    "In fact, they would have yield almost the same TF-IDF representation but gensim tends to throw away the zeros columns and there's no direct way to convert it into the sparse matrix representation so that we can put it into the `sklearn` classifier directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p9NqX3AbVcUH"
   },
   "source": [
    "## 2.2.2 `Transfer`: Learn a Classifier from the Vectors\n",
    "\n",
    "There's a whole range of classifiers from `sklearn` that can be used. <br>\n",
    "For detailed example, see http://scikit-learn.org/stable/auto_examples/text/document_classification_20newsgroups.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 746,
     "status": "ok",
     "timestamp": 1527744605282,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "aueu-rDbP5Hf",
    "outputId": "60992fd0-4455-4e38-f112-aa2ba944b0fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
       "      max_iter=10, n_iter=None, n_jobs=1, penalty=None, random_state=0,\n",
       "      shuffle=True, tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pick your poison.\n",
    "from sklearn.linear_model import Perceptron\n",
    "# Initialize your classifier.\n",
    "clf = Perceptron(max_iter=10)\n",
    "# Train the classifier.\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w_lLkkobZ1jQ"
   },
   "source": [
    "## 2.2.3 `Predict`: Make Predictions on Test/Unseen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 782,
     "status": "ok",
     "timestamp": 1527744609460,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "YPlCPta8Z2Gh",
    "outputId": "8fec8f61-6b39-43ca-cdfa-66b5624002d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False]\n",
      "(False, True)\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict(X_test))\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VBBbkFb9ZS5k"
   },
   "source": [
    "## Booo! So much for sophistication. \n",
    "\n",
    "Note that the task is to predict the existence of \"mr brown\" in the sentence. \n",
    "\n",
    "Wouldn't it makes more sense if the TF-IDF takes into consideration n-grams?\n",
    "\n",
    "\n",
    "## Lets try TF-IDF Transformation with Bi-grams!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 761,
     "status": "ok",
     "timestamp": 1527744612448,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "1MBp6PhzP8hi",
    "outputId": "949ae6fd-7499-4f95-c20c-29a49b05d4d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True]\n",
      "(False, True)\n"
     ]
    }
   ],
   "source": [
    "# Transform.\n",
    "vectorizer = TfidfVectorizer(input=train_texts, analyzer='word', \n",
    "                             ngram_range=(2,2),\n",
    "                             min_df = 0, stop_words=None)\n",
    "\n",
    "X_train =  vectorizer.fit_transform(train_texts)\n",
    "X_test =  vectorizer.transform(test_texts)\n",
    "\n",
    "y_train = train_labels\n",
    "y_test = test_labels\n",
    "\n",
    "# Transfer.\n",
    "clf = Perceptron(max_iter=10)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict.\n",
    "print(clf.predict(X_test))\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l1E8Zb6DaatZ"
   },
   "source": [
    "### Volia, Mr Brown is found !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f4calKgsccOi"
   },
   "source": [
    "\n",
    "# 잠시만요... (wait a minute) Where's the Deep Learning Stuff?\n",
    "\n",
    "> “The thing that hath been, it is that which shall be; and <br>\n",
    "that which is done is that which shall be done: and<br>\n",
    "there is no new thing under the sun.” <br>- Book of Ecclesiastes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W3UwO8osdlIN"
   },
   "source": [
    "\n",
    "\n",
    "In fact, the deep learning methods in solving most classification/regression task follows <br>the same (i) **`Transform`**, (ii) **`Transfer`** and (iii) **`Predict`** paradigm. \n",
    "\n",
    "Take for instance, the use of **neural embeddings** in NLP, the general idea is to:\n",
    "\n",
    " 1. **Transform**: Embed and encode the input text into a vector\n",
    " 2. **Transfer**: Learn the model to map from the vector to the training labels\n",
    " 3. **Predict**: Produce the output based on the model \n",
    "\n",
    "@SpaCy has a nice blogpost on this: https://explosion.ai/blog/deep-learning-formula-nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q1LsjtbvhwuZ"
   },
   "source": [
    "**Cut-away:** Why does `predict` deserve it's own step?\n",
    "\n",
    "> Actually, depending on which model is used to learn the mapping between the transformed <br>vector to the gold standards, \"prediction\" can be more than simply predicting a single output <br>label/number; e.g. it could be generating output sequence which needs some sort of \"decoder\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RyUOt25Qjki6"
   },
   "source": [
    "# 3.0 Vectorization Is All You Need\n",
    "\n",
    "For the *neural news chasers*, the **Attention Is All You Need (AIAYN)**  aka. **Transformer**<br>\n",
    "and **Deep Averaging Network (DAN)** neural architectures have been the new kids <br>\n",
    "on the block challenging the omni-potent **Recurrent Neural Network (RNN)** architectures, <br>\n",
    "notably the **Long-Short Term Memory (LSTM)**. \n",
    "\n",
    "\n",
    "### Riddikulus!\n",
    "\n",
    "If the above sounds like Harry Potter spells, yes it is. <br>\n",
    "But the **AIAYN**, **DAN**, **RNN** and **LSTM** seem equally elusive...\n",
    "\n",
    "For the mere mortals, we can think of them as vectorizers, like the TF-IDF. \n",
    "\n",
    "## 3.1. Universal Sentence Encoder\n",
    "\n",
    "The [**Universal Sentence Encoder**](https://www.tensorflow.org/hub/modules/google/universal-sentence-encoder/1) is a pre-trained model using the **DAN** / **Transformer** architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nCRjrNaLmM18"
   },
   "outputs": [],
   "source": [
    "# Install the latest Tensorflow version.\n",
    "!pip3 install --quiet \"tensorflow>=1.7\"\n",
    "# Install TF-Hub.\n",
    "!pip3 install --quiet tensorflow-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zK2hOoz1Rvgu"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Printing candies, make sure that arrays \n",
    "# are ellipsis and humanly readable.\n",
    "np.set_printoptions(precision=4, threshold=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vx1u9K7LVaW-"
   },
   "outputs": [],
   "source": [
    "# The URL that hosts the Transformer model for Universal Sentence Encoder \n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/1\"\n",
    "\n",
    "# The URL that hosts the DAN model for Universal Sentence Encoder \n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/1\"\n",
    "\n",
    "# On a local machine, uncomment the last two lines in this cell,\n",
    "# so that the mmodule don't get redownloaded multiple times.\n",
    "# when you run the notebook in different sessions.\n",
    "#\n",
    "# By setting `TFHUB_CACHE_DIR` environment variable,\n",
    "# it sets the directory where tf_hub will save the model.\n",
    "#\n",
    "##import os\n",
    "##os.environ[\"TFHUB_CACHE_DIR\"] = os.getcwd() + \"/tfhub_models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2749,
     "status": "ok",
     "timestamp": 1527826919479,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "g-NSgQM-miMQ",
    "outputId": "60c55c5f-12ed-408c-b29e-991c8524883c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_1/Embeddings_en/sharded_0:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Embeddings_en/sharded_0\n",
      "INFO:tensorflow:Initialize variable module_1/Embeddings_en/sharded_1:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Embeddings_en/sharded_1\n",
      "INFO:tensorflow:Initialize variable module_1/Embeddings_en/sharded_10:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Embeddings_en/sharded_10\n",
      "INFO:tensorflow:Initialize variable module_1/Embeddings_en/sharded_11:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Embeddings_en/sharded_11\n",
      "INFO:tensorflow:Initialize variable module_1/Embeddings_en/sharded_12:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Embeddings_en/sharded_12\n",
      "INFO:tensorflow:Initialize variable module_1/Embeddings_en/sharded_13:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Embeddings_en/sharded_13\n",
      "INFO:tensorflow:Initialize variable module_1/Embeddings_en/sharded_14:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Embeddings_en/sharded_14\n",
      "INFO:tensorflow:Initialize variable module_1/Embeddings_en/sharded_15:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Embeddings_en/sharded_15\n",
      "INFO:tensorflow:Initialize variable module_1/Embeddings_en/sharded_16:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Embeddings_en/sharded_16\n",
      "INFO:tensorflow:Initialize variable module_1/Embeddings_en/sharded_2:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Embeddings_en/sharded_2\n",
      "INFO:tensorflow:Initialize variable module_1/Embeddings_en/sharded_3:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Embeddings_en/sharded_3\n",
      "INFO:tensorflow:Initialize variable module_1/Embeddings_en/sharded_4:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Embeddings_en/sharded_4\n",
      "INFO:tensorflow:Initialize variable module_1/Embeddings_en/sharded_5:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Embeddings_en/sharded_5\n",
      "INFO:tensorflow:Initialize variable module_1/Embeddings_en/sharded_6:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Embeddings_en/sharded_6\n",
      "INFO:tensorflow:Initialize variable module_1/Embeddings_en/sharded_7:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Embeddings_en/sharded_7\n",
      "INFO:tensorflow:Initialize variable module_1/Embeddings_en/sharded_8:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Embeddings_en/sharded_8\n",
      "INFO:tensorflow:Initialize variable module_1/Embeddings_en/sharded_9:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Embeddings_en/sharded_9\n",
      "INFO:tensorflow:Initialize variable module_1/Encoder_en/DNN/ResidualHidden_0/weights:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Encoder_en/DNN/ResidualHidden_0/weights\n",
      "INFO:tensorflow:Initialize variable module_1/Encoder_en/DNN/ResidualHidden_1/weights:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Encoder_en/DNN/ResidualHidden_1/weights\n",
      "INFO:tensorflow:Initialize variable module_1/Encoder_en/DNN/ResidualHidden_2/weights:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Encoder_en/DNN/ResidualHidden_2/weights\n",
      "INFO:tensorflow:Initialize variable module_1/Encoder_en/DNN/ResidualHidden_3/projection:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Encoder_en/DNN/ResidualHidden_3/projection\n",
      "INFO:tensorflow:Initialize variable module_1/Encoder_en/DNN/ResidualHidden_3/weights:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Encoder_en/DNN/ResidualHidden_3/weights\n",
      "INFO:tensorflow:Initialize variable module_1/SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_0/bias:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_0/bias\n",
      "INFO:tensorflow:Initialize variable module_1/SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_0/weights:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_0/weights\n",
      "INFO:tensorflow:Initialize variable module_1/SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_1/bias:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_1/bias\n",
      "INFO:tensorflow:Initialize variable module_1/SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_1/weights:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_1/weights\n",
      "INFO:tensorflow:Initialize variable module_1/SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_2/bias:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_2/bias\n",
      "INFO:tensorflow:Initialize variable module_1/SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_2/weights:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_2/weights\n",
      "INFO:tensorflow:Initialize variable module_1/SNLI/Classifier/LinearLayer/bias:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with SNLI/Classifier/LinearLayer/bias\n",
      "INFO:tensorflow:Initialize variable module_1/SNLI/Classifier/LinearLayer/weights:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with SNLI/Classifier/LinearLayer/weights\n",
      "INFO:tensorflow:Initialize variable module_1/SNLI/Classifier/tanh_layer_0/bias:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with SNLI/Classifier/tanh_layer_0/bias\n",
      "INFO:tensorflow:Initialize variable module_1/SNLI/Classifier/tanh_layer_0/weights:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with SNLI/Classifier/tanh_layer_0/weights\n",
      "INFO:tensorflow:Initialize variable module_1/global_step:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with global_step\n"
     ]
    }
   ],
   "source": [
    "# Import the Universal Sentence Encoder's TF Hub module\n",
    "# This will take some time to download the model for the first time...\n",
    "embed = hub.Module(module_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BkbTYn8dpcam"
   },
   "source": [
    "## 3.1.1 Transform: Encode the Text Input into a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s2Xk7pzom5-3"
   },
   "outputs": [],
   "source": [
    "# Train sentences.\n",
    "sent0, label0 = \"The quick brown fox jumps over the lazy brown dog .\".lower() , False\n",
    "sent1, label1 = \"Mr brown jumps over the lazy fox .\".lower(), True\n",
    "sent2, label2 = \"Roses are red , the chocolates are brown .\".lower(), False\n",
    "sent3, label3 = \"The frank dog jumps through the red roses .\".lower(), False\n",
    "\n",
    "# Test sentences.\n",
    "sent4, label4 = \"Mr Tan jumps on red chocolates ?\".lower(), False\n",
    "sent5, label5 = \"Mr brown likes the lazy dog .\".lower(), True\n",
    "\n",
    "train_documents = [(sent0, label0), (sent1, label1), (sent2, label2), (sent0, label2)]\n",
    "test_documents = [(sent4, label4), (sent5, label5)]\n",
    "\n",
    "train_texts, train_labels = zip(*train_documents)\n",
    "test_texts, test_labels = zip(*test_documents)\n",
    "\n",
    "y_train = train_labels\n",
    "y_test = test_labels\n",
    "\n",
    "with tf.Session() as session:\n",
    "  session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "  X_train = sentence_embeddings = session.run(embed(train_texts))\n",
    "  X_test = test_embeddings = session.run(embed(test_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 776,
     "status": "ok",
     "timestamp": 1527826938528,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "zOax37BYn99b",
    "outputId": "0f247b14-dc2f-4028-d99d-67ca4e1973b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the quick brown fox jumps over the lazy brown dog .\n"
     ]
    }
   ],
   "source": [
    "print(sent0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1493,
     "status": "ok",
     "timestamp": 1527826940998,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "nr6Q-T7_oR41",
    "outputId": "43afc28a-9825-4b1e-e4f1-e508debe67f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.0208,  0.0175, -0.0132, ...,  0.0613, -0.0577, -0.0428],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Not unlike the TF-IDF model, the DAN embedding returns\n",
    "# an array of 512 floating points.\n",
    "print(len(sentence_embeddings[0]))\n",
    "sentence_embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 894,
     "status": "ok",
     "timestamp": 1527826947978,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "e-JGAJQcXWQH",
    "outputId": "d3efeefe-b866-4bf9-95c0-ffd28361e470"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 512)"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hTF1Crylpq4M"
   },
   "source": [
    "## 3.1.2 Transfer: Learn the Model to Map Sentence Vectors to Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 845,
     "status": "ok",
     "timestamp": 1527826951750,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "_vk4uzwPoSwT",
    "outputId": "e9da63ac-40d4-46ef-a0db-78b618ccab47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
       "      max_iter=10, n_iter=None, n_jobs=1, penalty=None, random_state=0,\n",
       "      shuffle=True, tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pick your poison.\n",
    "from sklearn.linear_model import Perceptron\n",
    "# Initialize your classifier.\n",
    "clf = Perceptron(max_iter=10)\n",
    "# Train the classifier.\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OwgvNlvOyA95"
   },
   "source": [
    "## 3.1.3 Predict: Make Predictions on the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1239,
     "status": "ok",
     "timestamp": 1527826954259,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "O2WZyYi7pp04",
    "outputId": "620686dd-7c86-491c-cde6-aff3c4743b02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True]\n",
      "(False, True)\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict(X_test))\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W3QjvanJyP_A"
   },
   "source": [
    "**Note:** In this case, we have **NOT** explicitly include the bigram information into the <br>\n",
    "TF-IDF but it's still learning the features correctly to predict the existence of \"mr brown\"!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uPgDrfX2yj0V"
   },
   "source": [
    "# 4.0 Mirrors, it must be mirrors! \n",
    "\n",
    "That's what I usually say when I don't really know how/why the magic works. <br>\n",
    "\n",
    "\n",
    "But the sentence vectors produced by the **Deep Averaging Network** model isn't smokes and magic, <br>\n",
    "we can easily replicate the TTP trick on other NLP tasks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wNe2mX1Iz3JK"
   },
   "source": [
    "# 4.1. Classifying Toxic Comments\n",
    "\n",
    "Lets apply what we learnt in a realistic task and **fight cyber-abuse with NLP**!\n",
    "\n",
    "From https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/\n",
    "\n",
    "> *The threat of abuse and harassment online means that many people stop <br>*\n",
    "> *expressing themselves and give up on seeking different opinions. <br>*\n",
    "> *Platforms struggle to effectively facilitate conversations, leading many <br>*\n",
    "> *communities to limit or completely shut down user comments.*\n",
    "\n",
    "\n",
    "The goal of the task is to build a model to detect different types of of toxicity:\n",
    "\n",
    " - toxic\n",
    " - severe toxic\n",
    " - threats\n",
    " - obscenity\n",
    " - insults\n",
    " - identity-based hate\n",
    " \n",
    " \n",
    "## Digging into the data..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HMLNyeIhlYwO"
   },
   "source": [
    "Lets download the [Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/) data using the [Kaggle API](https://github.com/Kaggle/kaggle-api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14006,
     "status": "ok",
     "timestamp": 1527827464437,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "CCvuk2nLzhHC",
    "outputId": "219fb408-e6ea-4eca-92a3-200e14d7b653"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.3.8)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.18.4)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2018.4.16)\n",
      "Requirement already satisfied: urllib3>=1.15 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.22)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.11.0)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
      "sample_submission.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
      "test.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
      "train.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
      "test_labels.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
      "Archive:  /content/.kaggle/competitions/jigsaw-toxic-comment-classification-challenge/sample_submission.csv.zip\n",
      "caution: filename not matched:  /content/.kaggle/competitions/jigsaw-toxic-comment-classification-challenge/test.csv.zip\n",
      "caution: filename not matched:  /content/.kaggle/competitions/jigsaw-toxic-comment-classification-challenge/test_labels.csv.zip\n",
      "caution: filename not matched:  /content/.kaggle/competitions/jigsaw-toxic-comment-classification-challenge/train.csv.zip\n"
     ]
    }
   ],
   "source": [
    "!pip3 install kaggle\n",
    "!mkdir -p /content/.kaggle/\n",
    "!echo '{\"username\":\"natgillin\",\"key\":\"54ae95ab760b52c3307ed4645c6c9b5d\"}' > /content/.kaggle/kaggle.json\n",
    "!chmod 600 /content/.kaggle/kaggle.json\n",
    "!kaggle competitions download -c jigsaw-toxic-comment-classification-challenge\n",
    "!unzip /content/.kaggle/competitions/jigsaw-toxic-comment-classification-challenge/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 937,
     "status": "ok",
     "timestamp": 1527827541469,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "U5LmQnUFyLhK",
    "outputId": "4ad1201a-c571-4bc0-fcf1-74a0ac03bdb9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_submission.csv.zip',\n",
       " 'test_labels.csv.zip',\n",
       " 'test.csv.zip',\n",
       " 'train.csv.zip']"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir('/content/.kaggle/competitions/jigsaw-toxic-comment-classification-challenge/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SrA_V_ItyO-u"
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = '/content/.kaggle/competitions/jigsaw-toxic-comment-classification-challenge/'\n",
    "\n",
    "with ZipFile(data_dir+'train.csv.zip', 'r') as zipfin:\n",
    "    train_csv = zipfin.open('train.csv')\n",
    "    df_train = pd.read_csv(train_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1473,
     "status": "ok",
     "timestamp": 1527827668130,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "7f4KAVgNO0Y3",
    "outputId": "3936ce1b-87ab-41ec-81ef-b99052ab5632"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is how the training data looks like.\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PKfeiG-9O1nL"
   },
   "outputs": [],
   "source": [
    "with ZipFile(data_dir+'test.csv.zip', 'r') as zipfin:\n",
    "    test_csv = zipfin.open('test.csv')\n",
    "    df_test = pd.read_csv(test_csv, index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EmlTe-9tHT-Y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 899,
     "status": "ok",
     "timestamp": 1527830026936,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "zVABL9j_oJvr",
    "outputId": "b9c4b795-ed48-4a34-9f53-1170350d3ab8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00001cee341fdb12</th>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000247867823ef7</th>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00013b17ad220c46</th>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00017563c3f7919a</th>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00017695ad8997eb</th>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       comment_text\n",
       "id                                                                 \n",
       "00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
       "0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
       "00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
       "00017563c3f7919a  :If you have a look back at the source, the in...\n",
       "00017695ad8997eb          I don't anonymously edit articles at all."
      ]
     },
     "execution_count": 83,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is how the test data looks like w/o the labels.\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HysGw6IKocHe"
   },
   "outputs": [],
   "source": [
    "with ZipFile(data_dir+'test_labels.csv.zip', 'r') as zipfin:\n",
    "    test_labels = zipfin.open('test_labels.csv')\n",
    "    df_test_labels = pd.read_csv(test_labels, index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1159,
     "status": "ok",
     "timestamp": 1527830039776,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "A9lC4QpAorhn",
    "outputId": "ba09d270-fef2-4b66-81eb-ae0d7752a28b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00001cee341fdb12</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000247867823ef7</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00013b17ad220c46</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00017563c3f7919a</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00017695ad8997eb</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "id                                                                           \n",
       "00001cee341fdb12     -1            -1       -1      -1      -1             -1\n",
       "0000247867823ef7     -1            -1       -1      -1      -1             -1\n",
       "00013b17ad220c46     -1            -1       -1      -1      -1             -1\n",
       "00017563c3f7919a     -1            -1       -1      -1      -1             -1\n",
       "00017695ad8997eb     -1            -1       -1      -1      -1             -1"
      ]
     },
     "execution_count": 85,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is how the test labels look like.\n",
    "df_test_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dq0C2JgfwxPW"
   },
   "outputs": [],
   "source": [
    "# Lets add them to the *df_test*\n",
    "df_test = df_test.join(df_test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BH8i5OAEp60u"
   },
   "source": [
    "## 4.1.1 Transform: Lets munge the data till we get our X (input vectors) and y (output labels)\n",
    "\n",
    "To simplify things, we can start with predicting just a single label `toxic` or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pvaIEly_ox_y"
   },
   "outputs": [],
   "source": [
    "# Internet connection is slow here, so lets use 100 train comments\n",
    "# instead of the full dataset.\n",
    "X_train_text = list(df_train['comment_text'])[:100]\n",
    "y_train = df_train['toxic'][:100]\n",
    "\n",
    "# Internet connection is slow here, so lets use 10 test comments\n",
    "# instead of the full dataset.\n",
    "X_test_text = list(df_test['comment_text'])[:10]\n",
    "\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "    X_train = sentence_embeddings = session.run(embed(X_train_text))\n",
    "    X_test = test_embeddings = session.run(embed(X_test_text))\n",
    "\n",
    "def transform_text_to_vectors():\n",
    "  X_train_text = list(df_train['comment_text'])\n",
    "  X_test_text = list(df_test['comment_text'])\n",
    "  with tf.Session() as session:\n",
    "    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "    X_train = sentence_embeddings = session.run(embed(X_train_text))\n",
    "    X_test = test_embeddings = session.run(embed(X_test_text))\n",
    "  return X_train, X_test\n",
    "\n",
    "\n",
    "## To use the full dataset, un-comment this line:\n",
    "##X_train, X_test = transform_text_to_vectors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PwLRS1ChoGEQ"
   },
   "source": [
    "We'll do some cheating and just load the embeddings from a pickle file that's previously ran the `transform_text_to_vectors()` function like this:\n",
    "\n",
    "\n",
    "```\n",
    "import pickle\n",
    "X_train, X_test = transform_text_to_vectors()\n",
    "\n",
    "with open('toxic_text_vector.test.pkl', 'wb') as fout:\n",
    "    pickle.dump(X_test, fout)\n",
    "    \n",
    "with open('toxic_text_vector.train.pkl', 'wb') as fout:\n",
    "    pickle.dump(X_train, fout)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14468,
     "status": "ok",
     "timestamp": 1527827946305,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "JWjxYStiouO-",
    "outputId": "28e03fa1-9597-45c9-bf85-18da794cc81c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic-comments-embeddings.zip: Downloaded 564MB of 564MB to /content/.kaggle/datasets/alvations/toxic-comments-embeddings\n"
     ]
    }
   ],
   "source": [
    "# Downloading the embeddings from https://www.kaggle.com/alvations/toxic-comments-embeddings/data\n",
    "! kaggle datasets download -d alvations/toxic-comments-embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1534,
     "status": "ok",
     "timestamp": 1527827984737,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "3mnyiL5bonPk",
    "outputId": "56832a4e-53c0-43a7-9ee2-b83ca1cc72e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['toxic_text_vector.test.pkl',\n",
       " 'toxic_text_vector.train.pkl',\n",
       " 'toxic-comments-embeddings.zip']"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's where the embeddings are downloaded.\n",
    "embed_dir = '/content/.kaggle/datasets/alvations/toxic-comments-embeddings/'\n",
    "os.listdir(embed_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JPhf6qyxpUKm"
   },
   "outputs": [],
   "source": [
    "# To load the pickled embeddings.\n",
    "import pickle\n",
    "with open(embed_dir+'toxic_text_vector.train.pkl', 'rb') as fin:\n",
    "  X_train = pickle.load(fin)\n",
    "  \n",
    "with open(embed_dir+'toxic_text_vector.test.pkl', 'rb') as fin:\n",
    "  X_test = pickle.load(fin)\n",
    "  \n",
    "# Remember to load all the labels too.\n",
    "y_train = df_train['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pYqQpstG1N8y"
   },
   "source": [
    "## 4.1.2 Transfer: Train the model using to map X -> y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 784,
     "status": "ok",
     "timestamp": 1527828158823,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "tbF9IqwQZOaa",
    "outputId": "f5af0f42-7737-4f03-b722-b524fca35b11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 512)"
      ]
     },
     "execution_count": 78,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape # Here's the full training dataset with 159,571 comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3412,
     "status": "ok",
     "timestamp": 1527828164273,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "l3ePEDCSrPAt",
    "outputId": "31b47c3d-5b59-4419-c21c-5428113a5c55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
       "      max_iter=10, n_iter=None, n_jobs=1, penalty=None, random_state=0,\n",
       "      shuffle=True, tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pick your poison.\n",
    "from sklearn.linear_model import Perceptron\n",
    "# Initialize your classifier.\n",
    "clf = Perceptron(max_iter=10)\n",
    "# Train the classifier.\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OYYWkLv7yVv_"
   },
   "outputs": [],
   "source": [
    "# Predict using our classifier and save our predictions.\n",
    "predictions = list(clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3546,
     "status": "ok",
     "timestamp": 1527830917088,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "J2hQThBi1tm1",
    "outputId": "5804c251-fa38-4cff-e500-a17d8ca21900"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: [\"Yo bitch Ja Rule is more succesful then you'll ever be whats up with you and hating you sad mofuckas...i should bitch slap ur pethedic white faces and get you to kiss my ass you guys sicken me. Ja rule is about pride in da music man. dont diss that shit on him. and nothin is wrong bein like tupac he was a brother too...fuckin white boys get things right next time.,\"]\n",
      "Correct label: -1\n",
      "Predicted label: 1\n",
      "\n",
      "Input text: ['== From RfC == \\n\\n The title is fine as it is, IMO.']\n",
      "Correct label: -1\n",
      "Predicted label: 0\n",
      "\n",
      "Input text: ['\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lapland —  /  \"']\n",
      "Correct label: -1\n",
      "Predicted label: 0\n",
      "\n",
      "Input text: [\":If you have a look back at the source, the information I updated was the correct form. I can only guess the source hadn't updated. I shall update the information once again but thank you for your message.\"]\n",
      "Correct label: -1\n",
      "Predicted label: 0\n",
      "\n",
      "Input text: [\"I don't anonymously edit articles at all.\"]\n",
      "Correct label: -1\n",
      "Predicted label: 0\n",
      "\n",
      "Input text: ['Thank you for understanding. I think very highly of you and would not revert without discussion.']\n",
      "Correct label: 0\n",
      "Predicted label: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lets just take a look at first 5 predictions.\n",
    "for i, ((idx, row), pred) in enumerate(zip(df_test.iterrows(), predictions)):\n",
    "  if i > 5: \n",
    "    break\n",
    "  print('Input text:', [row['comment_text']])\n",
    "  print('Correct label:', row['toxic'])\n",
    "  print('Predicted label:', pred)\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hB16lPtMBw2B"
   },
   "source": [
    "## Gotcha! What's -1? \n",
    "\n",
    "Our training data only has `1` or `0` as the label. Why are there `-1`?\n",
    "\n",
    "It's a quirk in leaderboard driven competition where not all of the test data is annotated and participants won't know which test data point is evaluated until the competition is over. \n",
    "\n",
    "From https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data \n",
    "\n",
    "> **test_labels.csv** - labels for the test data; value of -1 indicates it was not used for scoring; \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T0SDTLufx-jZ"
   },
   "source": [
    "\n",
    "## We just have to do some data munging when we evaluate our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fliI6kusx8eJ"
   },
   "outputs": [],
   "source": [
    "# Using http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html \n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "y_pred, y_actual = [], []\n",
    "\n",
    "for i, (actual, pred) in enumerate(zip(df_test['toxic'], predictions)):\n",
    "  if actual == -1: # Skip the rows with -1 values.\n",
    "    continue\n",
    "  y_pred.append(pred)\n",
    "  y_actual.append(actual)\n",
    "\n",
    "precision, recall, fscore, _ = precision_recall_fscore_support(y_actual, y_pred, average=\"weighted\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LiYdA4h9zuub"
   },
   "source": [
    "# Congratulations, you are now a defender of cyber-abuse!! \n",
    "\n",
    "\n",
    "You have built your first NLP classifier using sentence vectors (aka embeddings) to detect toxic comments!!\n",
    "\n",
    "And it performed pretty well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 792,
     "status": "ok",
     "timestamp": 1527831114106,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "0cWdoMzXz_yj",
    "outputId": "77c8b42e-d8e6-4462-bc48-fdd48817f3ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.9232154306102124\n",
      "Recall = 0.9309919034668167\n",
      "F-score = 0.9203367205545505\n"
     ]
    }
   ],
   "source": [
    "# Take a look at https://en.wikipedia.org/wiki/Precision_and_recall \n",
    "print('Precision =', precision)\n",
    "print('Recall =', recall)\n",
    "print('F-score =', fscore) # Usually we use the F-score as the overall gauge of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 859,
     "status": "ok",
     "timestamp": 1527831601991,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "FxAf3HU61ZG4",
    "outputId": "999b3351-8a4b-430a-b871-296a810a808c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# If we compare your classifier with one that always say the comment is non-toxic\n",
    "actual_labels = list(df_test[df_test['toxic'] != -1]['toxic'])\n",
    "predictions_allzeros = [0] * len(actual_labels)\n",
    "\n",
    "precision, recall, fscore, _ = precision_recall_fscore_support(actual_labels, predictions_allzeros, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1109,
     "status": "ok",
     "timestamp": 1527831634933,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "Y3vrGneT1_H3",
    "outputId": "96ef39c0-5b9f-4e6e-9913-9ea3f6682cbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If we always predict it's non-toxic...\n",
      "\n",
      "Precision = 0.8186829978220937\n",
      "Recall = 0.9048110287911469\n",
      "F-score = 0.8595949786595427\n"
     ]
    }
   ],
   "source": [
    "print(\"If we predict that comment is always non-toxic...\\n\")\n",
    "print('Precision =', precision)\n",
    "print('Recall =', recall)\n",
    "print('F-score =', fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 991,
     "status": "ok",
     "timestamp": 1527831721895,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "Jfpg9MAE3d-3",
    "outputId": "108bf762-fed3-471f-b536-828d5e057337"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# If we compare your classifier with one that always say the comment is non-toxic\n",
    "actual_labels = list(df_test[df_test['toxic'] != -1]['toxic'])\n",
    "predictions_allzeros = [1] * len(actual_labels)\n",
    "\n",
    "precision, recall, fscore, _ = precision_recall_fscore_support(actual_labels, predictions_allzeros, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 876,
     "status": "ok",
     "timestamp": 1527831723662,
     "user": {
      "displayName": "liling tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102844927690955683586"
     },
     "user_tz": -480
    },
    "id": "BTZPi6wC3OqB",
    "outputId": "0b405eff-7c9f-4dcc-df88-9b9983fe2699"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If we predict that comment is always toxic...\n",
      "\n",
      "Precision = 0.009060940239799854\n",
      "Recall = 0.09518897120885304\n",
      "F-score = 0.016546806949303966\n"
     ]
    }
   ],
   "source": [
    "print(\"If we predict that comment is always toxic...\\n\")\n",
    "print('Precision =', precision)\n",
    "print('Recall =', recall)\n",
    "print('F-score =', fscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lkYd0dzR6sH9"
   },
   "source": [
    "## And now...\n",
    "\n",
    "\n",
    "Hopefully, the notebook has walked you through your first steps in NLP with some \"deep learning\" (pre-trained models). To delve deeper, take a look at these:\n",
    "\n",
    " - https://www.kaggle.com/alvations/basic-nlp-with-nltk\n",
    " - https://explosion.ai/blog/deep-learning-formula-nlp\n",
    " - https://radimrehurek.com/gensim/tutorial.html\n",
    " - http://www.nltk.org/book\n",
    " \n",
    "\n",
    "Take a look at more pre-trained modules to \"transform\" texts into sentences:\n",
    " \n",
    "  - https://www.tensorflow.org/hub/\n",
    "\n",
    "\n",
    "Now, you have the tools and code ready to tackle almost any NLP problems with the same 3-Steps, (i) transform, (ii) transfer and (iii) predict.\n",
    "\n",
    "\n",
    "- Download the notebook\n",
    "- Go home and run it with proper internet\n",
    "- Re-run the notebook and rebuild the toxicity model for other labels\n",
    "- Play around with other NLP datasets\n",
    "\n",
    " \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UW0qZZon4Zej"
   },
   "source": [
    "# So Long and Thank You for the Fish!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Attap.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
